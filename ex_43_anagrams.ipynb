{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99146e9",
   "metadata": {},
   "source": [
    "# Of anagrams, probability, entropy, and tyPhon ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb687c17",
   "metadata": {},
   "source": [
    "I found Exercise  43 in [Torbjorn Lager](https://www.gu.se/en/about/find-staff/torbjornlager)'s list of [46 Python exercises](https://github.com/PabloVallejo/python-exercises/blob/master/exercises-list.md) oddly mesmerising, and could not stop playing. Here are a few notes I have put together for the amusement of my Python students and of some of my friends who also enjoy word games, probabilities, entropy, programming, and stuff. The text of the exercise is this:\n",
    "\n",
    "--------\n",
    "\n",
    "An anagram is a type of word play, the result of rearranging the letters of a word or phrase to produce a\n",
    "new word or phrase, using all the original letters exactly once; e.g., orchestra ~ carthorse. Using the word\n",
    "list  [unixdict.txt](https://raw.githubusercontent.com/quinnj/Rosetta-Julia/master/unixdict.txt), write a program that finds the sets of words that\n",
    "share the same characters that contain the most words in them.\n",
    "\n",
    "-------\n",
    "\n",
    "I have updated the link to the dictionary and uploaded it to this binder, so you can just run the code below (for those of you who are not familiar with [Jupyter Notebooks](https://jupyter.org/): click on the Run button above to run each code cell or on the \"Fast Forward\" button to run them all, you can edit the notebook and experiment as you wish).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e505c",
   "metadata": {},
   "source": [
    "## Solving the exercise\n",
    "\n",
    "This exercise is actually not that hard, once you realise that you can efficiently check if a word is the anagram of another by sorting their characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_chars(word):\n",
    "    \"\"\" Return a tuple containing the characters of word in alphabetical order \"\"\"\n",
    "    wlist=list(word)\n",
    "    wlist.sort()\n",
    "    return tuple(wlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8f528",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_chars(\"orchestra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46421c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_chars(\"carthorse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f158b",
   "metadata": {},
   "source": [
    "We want tuples because we are going to use these as keys in a dictionary for our usual counting trick. A string would do just as well, lists are no good because they are mutable and therefore not hashable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e678d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups={} # keys: sorted chars; values: list of words sharing those exact chars\n",
    "wcount=0\n",
    "with open(\"unixdict.txt\", \"rt\") as INFILE:\n",
    "    for word in INFILE:\n",
    "        word=word.rstrip() # remove \\n\n",
    "        wkey = sort_chars(word)\n",
    "        try:\n",
    "            # if we have seen the key before, add word to the anagram group\n",
    "            groups[wkey].append(word)\n",
    "        except KeyError: \n",
    "            # never seen wkey before - create new group for it\n",
    "            groups[wkey]=[word]            \n",
    "        wcount+=1\n",
    "    \n",
    "print(f\"{wcount} words processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa88359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary is big!\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb73ef",
   "metadata": {},
   "source": [
    "So how big is the largest set of words that are the anagram of each other? We can write a comprehension to find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxsize=max([len(wg) for wg in groups.values()])\n",
    "maxsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a114f",
   "metadata": {},
   "source": [
    "Let's find those groups of words - there may be more than one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fbb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "largest_groups=[]\n",
    "for wlist in groups.values():\n",
    "    if len(wlist)==5:\n",
    "        largest_groups.append(wlist)\n",
    "\n",
    "for group in largest_groups:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc01ff67",
   "metadata": {},
   "source": [
    "In fact, there are six. \n",
    "\n",
    "That's it for the exercise..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea84095",
   "metadata": {},
   "source": [
    "## ... what about the other groups?\n",
    "\n",
    "I suspect if we consider smaller groups of anagrams, we'll find more. Let's turn the code above into a function and check that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_group_size(groups, n):\n",
    "    listed_groups=[]\n",
    "    for wlist in groups.values():\n",
    "        if len(wlist)==n:\n",
    "            listed_groups.append(wlist)\n",
    "    return listed_groups\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb01a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_group_size(groups, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0df02e",
   "metadata": {},
   "source": [
    "As you'd expect, there are even more groups of three words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(select_group_size(groups, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd29462",
   "metadata": {},
   "source": [
    "In fact, we can plot the number of groups as a function of their size. Let's write a little helper object to aid with the counting, it'll come in handy even later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregate:\n",
    "    \"\"\" Aggregate a list of (x,y) pairs passed to the constructor with respect to x \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \"\"\" Initialise the object by aggregating data wrt the first component of the pairs \"\"\"\n",
    "        self._histogram={}\n",
    "        # do the actual aggregation here\n",
    "        for (hbin, hval) in data:\n",
    "            self._histogram[hbin]=self._histogram.get(hbin, 0)+hval\n",
    "            \n",
    "    def get(self, hbin):\n",
    "        \"\"\" returns the value associated to a bin, or zero if the bin does not exist \"\"\"\n",
    "        return self._histogram.get(hbin, 0)\n",
    "    \n",
    "    def low_bin(self):\n",
    "        \"\"\" returns the lowest non-zero bin \"\"\"\n",
    "        return min(self._histogram.keys())\n",
    "    \n",
    "    def high_bin(self):\n",
    "        \"\"\" return the highest non-zero bin \"\"\"\n",
    "        return max(self._histogram.keys())\n",
    "    \n",
    "    def get_range(self):\n",
    "        \"\"\" return a range object for integer bins (with missing values filled in),\n",
    "        a list of sorted bin labels in the other cases \"\"\"\n",
    "        try:\n",
    "            return range(self.low_bin(), self.high_bin()+1)\n",
    "        except TypeError: # bins are not int\n",
    "            return sorted(self._histogram.keys())\n",
    "    \n",
    "    def get_list(self, hbins=None):\n",
    "        \"\"\" return values on the list of bins passed, or on the entire range\n",
    "        if no list is passed \"\"\"\n",
    "        if hbins==None:\n",
    "            hbins=self.get_range()\n",
    "        return [self.get(b) for b in hbins]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911fbd40",
   "metadata": {},
   "source": [
    "Back to computing the number of groups as a function of their size. Let's have each group vote for its size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fedf122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each group counts for 1\n",
    "group_sizes=[(len(v), 1) for v in groups.values()]\n",
    "group_size_histo=Aggregate(group_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bedd227",
   "metadata": {},
   "source": [
    "As expected, here is the result - note that groups of size one mean no anagram at all for that word! That's of course the majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ea935",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size_histo.get_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc8acd8",
   "metadata": {},
   "source": [
    "We can even plot a nice graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01909aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# embed plots in notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35773de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better leave \"singleton\" words out or they will dwarf all the rest\n",
    "bins=range(2, group_size_histo.high_bin()+1)\n",
    "plt.bar(bins, group_size_histo.get_list(bins), tick_label=bins)\n",
    "plt.title('Anagram groups vs words they contain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc610c",
   "metadata": {},
   "source": [
    "## ...so what about word length? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f1776",
   "metadata": {},
   "source": [
    "Almost all the anagram groups we have seen consist of words of 4 or 5 letters, a few have 3 letters or 6. So what about other word lengths? What is the longest anagram in the dictionary? Let's try to find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select len(v)>1 because we want the word to have some anagram! \n",
    "maxlength= max([len(k) for k,v  in groups.items() if len(v)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622dcba",
   "metadata": {},
   "source": [
    "Again, we can write a function that finds groups with words of a given length for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d61da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_word_length(groups, l):\n",
    "    anagrams=[]\n",
    "    for k,wg in groups.items():\n",
    "        if len(k)==l and len(wg)> 1:\n",
    "            anagrams.append(wg)\n",
    "    return anagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c456270e",
   "metadata": {},
   "source": [
    "and here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300440cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_word_length(groups, maxlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695687eb",
   "metadata": {},
   "source": [
    "again, there seem to be more hits for shorter words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_word_length(groups, maxlength-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00d38ee",
   "metadata": {},
   "source": [
    "...and even more for even shorter words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_word_length(groups, maxlength-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c97f6a",
   "metadata": {},
   "source": [
    "at ```maxlength-3```, we even find a group of three words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c032d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_word_length(groups, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5e532",
   "metadata": {},
   "source": [
    "(I never suspected ```cartesian``` of being related to ```sectarian```, but that's now ```ascertain```'d).\n",
    "\n",
    "As before, we can plot a neat little histogram. We can count the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each groups casts a vote for the length of its words\n",
    "wlengths=[(len(k),1) for k,v in groups.items() if len(v)>1]\n",
    "groups_by_wlen=Aggregate(wlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702aa54",
   "metadata": {},
   "source": [
    "or we can count the individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each word in an anagram group casts a vote for its length\n",
    "wlengths=[(len(k),len(v)) for k,v in groups.items() if  len(v)>1]\n",
    "anagrams_by_wlen=Aggregate(wlengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8cf37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=range(2, maxlength+1)\n",
    "\n",
    "ax = plt.subplot(111) # get a handle for the axes\n",
    "h1=ax.bar([x-0.15 for x in bins], groups_by_wlen.get_list(bins), \n",
    "       width=0.3, align='center')\n",
    "# h1, h2 are handles for the bar series\n",
    "h2=ax.bar([x+0.15 for x in bins], anagrams_by_wlen.get_list(bins), \n",
    "       width=0.3, align='center')\n",
    "plt.legend([h1,h2], ['groups', 'anagrams'])\n",
    "plt.title('No of groups/anagrams vs word length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5aebf",
   "metadata": {},
   "source": [
    "Either way, we see a clear maximum for words of length 4, followed by words of length 5.\n",
    "Most anagrams are around this length. Surely that's because a majority of words in the dictionary are of length 4? Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each key corresponds to len(v) words of length len(k). Here even 'singleton' words count\n",
    "wlength=[(len(k), len(v)) for k,v in groups.items()]\n",
    "uxdict_by_length=Aggregate(wlength)\n",
    "\n",
    "bins=range(1, uxdict_by_length.high_bin()+1)\n",
    "plt.bar(bins, uxdict_by_length.get_list(bins), tick_label=bins)\n",
    "plt.title('Unixdict words vs length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f19fd5",
   "metadata": {},
   "source": [
    "Hold on! The most common word length in the dictionary is actually 7 characters. So where are all the groups of 7 or 8 letter long anagrams? Are we missing anything here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a917fd",
   "metadata": {},
   "source": [
    "## A simple probabilistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dac32",
   "metadata": {},
   "source": [
    "This discrepancy must be down to some combinatorial effect of word size. In fact, for two words to be the anagram of each other, they must \n",
    "* be of the same length, and\n",
    "* be one the permutation of the other.\n",
    "\n",
    "Now the first factor,as we have seen, favours words of length close to 7, but what about the second?\n",
    "\n",
    "For the second factor, consider the probability that two coins that you throw on the floor at random land on the same tile. You throw one coin first, and note the tile it landed on. Clearly now, the probability that the second coin will land on the same tile is equal to the area of that tile, divided by the size of the room. Now for two words of length $l$, the size of the room is the set of all sequences of length $l$ that can be formed with the 26 letters of the alphabet, that is $26^l$. Given a choice of letters (which is where the first coin lands), the size of the tile corresponds to all possible permutations of such letters, that is $l!$. Thus we can approximate the probability that two words are the anagrams of each other given that both of them are of length $l$ as:\n",
    "\\begin{equation}\n",
    "P(anagram|l,l)=\\frac{l!}{26^l}.\n",
    "\\end{equation}\n",
    "Of course the probability that they form an anagram pair given that they have different lengths is zero. This model is obviously very crude. For one thing, it treats words purely as random sequences of characters. However, we can as a first approximation assume that the rules that govern word formation apply evenly across the space of sequences, and so do not affect our calculation. Besides, our model assumes all characters are equally likely to occur in words, which is certainly not the case. However, this simple model still captures some important information.  Note in particular that, since all words in the dictionary are shorter than 26 characters, the numerator becomes progressively smaller as compared to the denominator, in the range we are interested in. In fact, $P(anagram|l,l)$ decreases very steeply with word length (note the log scale): <a id='alphabet_size'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to come back and change this later, \n",
    "# read on for now!\n",
    "alphabet_size=26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5476233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import  factorial\n",
    "\n",
    "xaxis=range(2,23)\n",
    "p_anagram_ll=[factorial(l)/alphabet_size**l for l in xaxis]\n",
    "plt.plot(xaxis, p_anagram_ll, marker='.', linestyle='')\n",
    "plt.xticks(xaxis)\n",
    "plt.yscale('log')\n",
    "plt.title(\"P(anagram|l,l) vs word length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da432eb",
   "metadata": {},
   "source": [
    "this term therefore suggests that, even if longer words are more common, they may have a smaller chance of forming an anagram pair simply because the possible permutations of a word form an increasingly small subset of the space of possible words (interestingly, note that this would not be the case for much longer words or alphabets with fewer letters, or indeed if some characters are used but rarely). We can therefore hope that combining this factor with the probability distribution of word length will lead to a realistic estimate for the probability of anagrams of a given length. \n",
    "\n",
    "In detail we have, for the probability of two words forming an anagram pair of length $l$:\n",
    "\\begin{equation}\n",
    "P(anagram, l, l)=P(anagram|l,l) P(l) P(l)\n",
    "\\end{equation}\n",
    "where $P(l)$ is the probability that a word has length $l$. This we can estimate from the length distribution of words in our dictionary, as computed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe20db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are not really interested in words of length 1, so start from 2\n",
    "ubl=uxdict_by_length.get_list(range(2,23))\n",
    "# normalise the counts so that probabilities sum to 1\n",
    "p_l=[l/sum(ubl) for l in ubl]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e9583",
   "metadata": {},
   "source": [
    "and therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52203ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each value in this list is P(anagram,l,l)\n",
    "p_anagram=[(pa_ll*pl*pl) for pa_ll, pl in zip(p_anagram_ll, p_l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23761bc5",
   "metadata": {},
   "source": [
    "In order to obtain a word count, we need to multiply this by twice the number of pair of \n",
    "words from the dictionary. Out of $N$ items we can form $N(N-1)/2$ pairs, hence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the first element is l=2, and we are not interested in anything \n",
    "# beyond the length of the longest anagram\n",
    "n_anagrams=[p *wcount*(wcount-1) for p in p_anagram[:maxlength-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2b148a",
   "metadata": {},
   "source": [
    "we can plot this against the data for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baea323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines\n",
    "\n",
    "bins=range(2, maxlength+1)\n",
    "ax = plt.subplot(111)\n",
    "h1=ax.bar(bins, anagrams_by_wlen.get_list(bins), color='tab:blue', align='center')\n",
    "ax.plot(bins, n_anagrams, marker='d', color='tab:orange', linestyle='')\n",
    "# proxy line with no data for creating the legend - plot returns no usable handle\n",
    "h2= mlines.Line2D([], [], color='tab:orange', marker='d', linestyle='None')\n",
    "plt.legend([h1,h2], ['actual', 'model'])\n",
    "plt.title('No of anagrams vs word length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12d17b",
   "metadata": {},
   "source": [
    "As can be seen, the maximum is in the right position, and the general shape of the curve appears to be correct. However, anagrams of length three are wrongly predicted to be more likely than those of length five; also, our model grossly underestimates the number of anagrams. This is really not surprising - we made some coarse approximations, and our model contains no information at all about the language. Rather, it is surprising that simple back-of-the envelope calculations manage to capture at least the general trend!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c77d4e",
   "metadata": {},
   "source": [
    "## Random dealings in entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a27d3",
   "metadata": {},
   "source": [
    "The fact that our model underestimates the number of anagrams suggests that we may have overestimated the denominator in our combinatorial factor $P(anagram|l,l)$. In fact, not all letters are equally likely to occur in a word. We can estimate the relative frequency of characters in the English language from our dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a large comprehension, using round brackets to delimit it turns it into\n",
    "# a generator, that's computed lazily when needed. Note the nested loops. The final\n",
    "# if is needed to filter out characters such as digits that also appear in the dictionary.\n",
    "# Each char in a key is counted once for every word in the corresponding group\n",
    "charlist=((c, len(v)) for k,v in groups.items() for c in k if c.isalpha())\n",
    "char_histo=Aggregate(charlist)\n",
    "all_letters=char_histo.get_range()\n",
    "char_counts=char_histo.get_list(all_letters)\n",
    "char_probs=[n/sum(char_counts) for n in char_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(all_letters, char_probs, tick_label=all_letters)\n",
    "plt.title('Character probability distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162d49a",
   "metadata": {},
   "source": [
    "As can be seen, 'e' is the most frequent letter in English, followed by 'a'; a few letters such as 'j', 'q', 'x' and 'z' are actually very rare. This suggests that there may be, in some sense, an \"effective\" alphabet size that's smaller than 26 characters. We can estimate that using [Shannon's entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)), that measures the minimum bit rate required to encode a sequence, given the probability distribution over the characters. In our case, Shannon's entropy can be computed as\n",
    "\\begin{equation}\n",
    "H=\\sum_c P(c)\\log_2\\left(\\frac{1}{P(c)}\\right)=-\\sum_c P(c)\\log_2 P(c)\n",
    "\\end{equation}\n",
    "where the sum is over all characters and $\\log_2 x$ is the logarithm of $x$ in base $2$ (for instance, $\\log_2 8 = 3$ since $2^3=8$). Shannon's entropy is measured in bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fce0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "H=sum([-p*log2(p) for p in char_probs])\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd00e2",
   "metadata": {},
   "source": [
    "This value of $H\\simeq 4.24\\,\\mathrm{bit}$ is significantly lower than the entropy of a uniform distribution over an alphabet of $26$ characters, that would be $\\log_2 26 \\simeq 4.70\\,\\mathrm{bit}$. Of course, our alphabet really has 26 characters, but they are not uniformly distributed. We can replace it in our model with a hypothetical, uniformly distributed alphabet of smaller size, so that its entropy has the correct value for English text; for that, the number of character needs to be equal to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "2**H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090658b9",
   "metadata": {},
   "source": [
    "If you now [scroll back up](#alphabet_size) and change ```alphabet_size``` to this \"effective size\" of $18.87\\simeq 19$ characters, and then run the calculations in the previous section again, you will see that this new model, while by no means perfect, fits the data a lot better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31574db1",
   "metadata": {},
   "source": [
    "## That's all, folks...\n",
    "\n",
    "All that's left is finding a nice little anagram for the title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280394f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"python\" # change this as suits\n",
    "\n",
    "print (\"Anagrams for \"+ query)\n",
    "key=sort_chars(query)\n",
    "try:\n",
    "    wl=groups[key]\n",
    "    if len(wl)>1:\n",
    "        print([w for w in wl if w!=query])\n",
    "    else:\n",
    "        print (\"None found!\")\n",
    "except KeyError:\n",
    "    print (\"Word not in wordlist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779dd86",
   "metadata": {},
   "source": [
    "(C) 2021 [Fabrizio Smeraldi](http://www.eecs.qmul.ac.uk/~fabri/) - All rights reserved. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
